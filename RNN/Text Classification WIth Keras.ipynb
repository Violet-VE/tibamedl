{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 对数据集的标签数据进行编码\n",
    "train_y = train_df.label\n",
    "val_y = val_df.label\n",
    "test_y = test_df.label\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train_y).reshape(-1,1)\n",
    "val_y = le.transform(val_y).reshape(-1,1)\n",
    "test_y = le.transform(test_y).reshape(-1,1)\n",
    "\n",
    "## 对数据集的标签数据进行one-hot编码\n",
    "ohe = OneHotEncoder()\n",
    "train_y = ohe.fit_transform(train_y).toarray()\n",
    "val_y = ohe.transform(val_y).toarray()\n",
    "test_y = ohe.transform(test_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用Tokenizer对词组进行编码\n",
    "## 当我们创建了一个Tokenizer对象后，使用该对象的fit_on_texts()函数，以空格去识别每个词,\n",
    "## 可以将输入的文本中的每个词编号，编号是根据词频的，词频越大，编号越小。\n",
    "max_words = 5000\n",
    "max_len = 600\n",
    "tok = Tokenizer(num_words=max_words)  ## 使用的最大词语数为5000\n",
    "tok.fit_on_texts(train_df.cutword)\n",
    "\n",
    "## 使用word_index属性可以看到每次词对应的编码\n",
    "## 使用word_counts属性可以看到每个词对应的频数\n",
    "for ii,iterm in enumerate(tok.word_index.items()):\n",
    "    if ii < 10:\n",
    "        print(iterm)\n",
    "    else:\n",
    "        break\n",
    "print(\"===================\")  \n",
    "for ii,iterm in enumerate(tok.word_counts.items()):\n",
    "    if ii < 10:\n",
    "        print(iterm)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 对每个词编码之后，每句新闻中的每个词就可以用对应的编码表示，即每条新闻可以转变成一个向量了：\n",
    "train_seq = tok.texts_to_sequences(train_df.cutword)\n",
    "val_seq = tok.texts_to_sequences(val_df.cutword)\n",
    "test_seq = tok.texts_to_sequences(test_df.cutword)\n",
    "## 将每个序列调整为相同的长度\n",
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "val_seq_mat = sequence.pad_sequences(val_seq,maxlen=max_len)\n",
    "test_seq_mat = sequence.pad_sequences(test_seq,maxlen=max_len)\n",
    "\n",
    "print(train_seq_mat.shape)\n",
    "print(val_seq_mat.shape)\n",
    "print(test_seq_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义LSTM模型\n",
    "inputs = Input(name='inputs',shape=[max_len])\n",
    "## Embedding(词汇表大小,batch大小,每个新闻的词长)\n",
    "layer = Embedding(max_words+1,128,input_length=max_len)(inputs)\n",
    "layer = LSTM(128)(layer)\n",
    "layer = Dense(128,activation=\"relu\",name=\"FC1\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(10,activation=\"softmax\",name=\"FC2\")(layer)\n",
    "model = Model(inputs=inputs,outputs=layer)\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=RMSprop(),metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(train_seq_mat,train_y,batch_size=128,epochs=10,\n",
    "                      validation_data=(val_seq_mat,val_y),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)] ## 当val-loss不再提升时停止训练\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre = model.predict(test_seq_mat)\n",
    "\n",
    "## 评价预测效果，计算混淆矩阵\n",
    "confm = metrics.confusion_matrix(np.argmax(test_pre,axis=1),np.argmax(test_y,axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
