{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorFlow 辨識手寫數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/05/cd/c171d2e33c0192b04560ce864c26eba83fed888fe5cd9ded661b2702f2ae/tensorflow-1.12.0-cp36-cp36m-win_amd64.whl (45.9MB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/df/d606d07cff0fc8d22abcc54006c0247002d11a7f2d218eb008d48e76851d/protobuf-3.6.1-cp36-cp36m-win_amd64.whl\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from tensorflow) (1.14.3)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/90/520757ccafb14f03e8e46a54bacd45f5f9cca6b96b58b83b66a272f059df/grpcio-1.16.0-cp36-cp36m-win_amd64.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/d0/65fe48383146199f16dbd5999ef226b87bce63ad5cd73c840cf722637969/tensorboard-1.12.0-py3-none-any.whl (3.0MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3_2\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl\n",
      "Installing collected packages: protobuf, gast, termcolor, astor, absl-py, grpcio, keras-preprocessing, keras-applications, markdown, tensorboard, tensorflow\n",
      "Successfully installed absl-py-0.6.1 astor-0.7.1 gast-0.2.0 grpcio-1.16.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 markdown-3.0.1 protobuf-3.6.1 tensorboard-1.12.0 tensorflow-1.12.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a52087e6ef24>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\USER\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\USER\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting C:\\Users\\USER\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\USER\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3_2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"C:\\\\Users\\\\USER\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000000000DB7A358>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000000100BF3C8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000000000F573400>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_asdict', '_fields', '_make', '_replace', '_source', 'count', 'index', 'test', 'train', 'validation']\n"
     ]
    }
   ],
   "source": [
    "print(dir(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_epochs_completed', '_images', '_index_in_epoch', '_labels', '_num_examples', 'epochs_completed', 'images', 'labels', 'next_batch', 'num_examples']\n"
     ]
    }
   ],
   "source": [
    "print(dir(mnist.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = mnist.train.images[0].reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11a3ccc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定網路參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   = 0.001\n",
    "training_epochs = 15\n",
    "batch_size      = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "n_samples  = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構多層神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):  \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定代價函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化變量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsamp,ysamp = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsamp,ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11a98710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sample_image = Xsamp.reshape((28,28))\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Equal:0' shape=(?,) dtype=bool>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=162.7127539617364\n",
      "Epoch: 2 cost=60.175241857008494\n",
      "Epoch: 3 cost=43.90214457815342\n",
      "Epoch: 4 cost=35.39966048847546\n",
      "Epoch: 5 cost=29.56505994363263\n",
      "Epoch: 6 cost=25.65166115305641\n",
      "Epoch: 7 cost=22.703955215974272\n",
      "Epoch: 8 cost=20.195572472919114\n",
      "Epoch: 9 cost=18.367894876870228\n",
      "Epoch: 10 cost=16.83057081796907\n",
      "Epoch: 11 cost=15.625885284163736\n",
      "Epoch: 12 cost=14.391746202978243\n",
      "Epoch: 13 cost=13.504779600988734\n",
      "Epoch: 14 cost=12.501692919216358\n",
      "Epoch: 15 cost=11.818564327512256\n",
      "0.9095\n",
      "Training Completed in 15 Epochs\n"
     ]
    }
   ],
   "source": [
    "# Start the session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Intialize all the variables\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Initial the cost = 0.0\n",
    "        avg_cost = 0.0\n",
    "\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch: {} cost={}\".format(epoch+1,avg_cost))\n",
    "    print(accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "print(\"Training Completed in {} Epochs\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-e2c76ffd417d>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\USER\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:\\Users\\USER\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting C:\\Users\\USER\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\USER\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"C:\\\\Users\\\\USER\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   = 0.001\n",
    "training_epochs = 15\n",
    "batch_size      = 100\n",
    "\n",
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "n_samples  = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(\"float\", [None, n_input],   name= 'input_x')\n",
    "    y = tf.placeholder(\"float\", [None, n_classes], name= 'input_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "    image_input = tf.reshape(x,[-1,28,28,1])\n",
    "    tf.summary.image('input', image_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(x, input_tensors, output_tensors, layer_name, activation_function = None):  \n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            weight = tf.Variable(tf.random_normal([input_tensors, output_tensors]), name = 'w')\n",
    "            tf.summary.histogram(name = layer_name + '/Weights', values = weight)\n",
    "        with tf.name_scope('Bias'):\n",
    "            bias = tf.Variable(tf.random_normal([output_tensors]), name= 'b')\n",
    "            tf.summary.histogram(name = layer_name + '/Bias', values = bias)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            formula = tf.add(tf.matmul(x, weight), bias)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        tf.summary.histogram(name = layer_name + '/Outputs', values = outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = add_layer(x, input_tensors = n_input, output_tensors = n_hidden_1, layer_name='layer1',activation_function = tf.nn.relu)\n",
    "layer2 = add_layer(layer1, input_tensors = n_hidden_1, output_tensors = n_hidden_2, layer_name='layer2',activation_function = tf.nn.relu)\n",
    "out_layer = add_layer(layer2, input_tensors = n_hidden_2, output_tensors = n_classes, layer_name='out_layer',activation_function = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-39-85aab1677ab7>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=y))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=166.012001093084\n",
      "Epoch: 2 cost=60.311729944402494\n",
      "Epoch: 3 cost=43.98361761613327\n",
      "Epoch: 4 cost=35.427545705275094\n",
      "Epoch: 5 cost=29.88471435243432\n",
      "Epoch: 6 cost=26.094324928196983\n",
      "Epoch: 7 cost=23.083716003244568\n",
      "Epoch: 8 cost=20.779412655613665\n",
      "Epoch: 9 cost=18.91421560352501\n",
      "Epoch: 10 cost=17.25629793123767\n",
      "Epoch: 11 cost=15.885236131277953\n",
      "Epoch: 12 cost=14.752916832620437\n",
      "Epoch: 13 cost=13.687327390909202\n",
      "Epoch: 14 cost=12.788714196085936\n",
      "Epoch: 15 cost=12.0156517796083\n",
      "Training Completed in 15 Epochs\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    ## Merge Summary\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"tensorboard2/\", graph = sess.graph)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c, result = sess.run([optimizer, cost, merged], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "            ## Adding summary of each step\n",
    "            writer.add_summary(result,  epoch * total_batch + i)\n",
    "\n",
    "        print(\"Epoch: {} cost={}\".format(epoch+1,avg_cost))\n",
    "\n",
    "    print(\"Training Completed in {} Epochs\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "- tensorboard --logdir tensorboard/ --host 127.0.0.1\n",
    "- http://127.0.0.1:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3_2\\lib\\site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b9a5c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test  = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test  /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes  = 10 \n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定網路參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape=(n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dense = activation_function(X * Weight + Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.0372 - acc: 0.7613 - val_loss: 0.4770 - val_acc: 0.8814\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4166 - acc: 0.8891 - val_loss: 0.3480 - val_acc: 0.9003\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3397 - acc: 0.9055 - val_loss: 0.3041 - val_acc: 0.9123\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.3033 - acc: 0.9141 - val_loss: 0.2776 - val_acc: 0.9201\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2788 - acc: 0.9208 - val_loss: 0.2588 - val_acc: 0.9247\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2598 - acc: 0.9258 - val_loss: 0.2429 - val_acc: 0.9307\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2437 - acc: 0.9307 - val_loss: 0.2337 - val_acc: 0.9325\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2298 - acc: 0.9349 - val_loss: 0.2227 - val_acc: 0.9355\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2176 - acc: 0.9386 - val_loss: 0.2092 - val_acc: 0.9384\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2064 - acc: 0.9416 - val_loss: 0.2015 - val_acc: 0.9400\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1964 - acc: 0.9447 - val_loss: 0.1919 - val_acc: 0.9441\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1872 - acc: 0.9469 - val_loss: 0.1827 - val_acc: 0.9448\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1789 - acc: 0.9492 - val_loss: 0.1764 - val_acc: 0.9471\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1713 - acc: 0.9519 - val_loss: 0.1702 - val_acc: 0.9493\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1643 - acc: 0.9537 - val_loss: 0.1645 - val_acc: 0.9506\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(model.predict(x_test), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predicted == y)  / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 965,    0,    0,    1,    0,    5,    5,    1,    2,    1],\n",
       "       [   0, 1115,    2,    2,    1,    1,    3,    2,    9,    0],\n",
       "       [   8,    3,  966,   10,    4,    4,    9,   10,   15,    3],\n",
       "       [   1,    1,    9,  960,    0,   16,    1,   10,    9,    3],\n",
       "       [   1,    1,    4,    1,  936,    0,    8,    3,    5,   23],\n",
       "       [  10,    2,    0,   14,    4,  836,   10,    1,   10,    5],\n",
       "       [   8,    3,    4,    1,   11,   12,  917,    0,    2,    0],\n",
       "       [   2,   10,   21,    7,    3,    1,    0,  960,    3,   21],\n",
       "       [   3,    3,    4,   16,    8,    8,   10,    7,  910,    5],\n",
       "       [   6,    8,    1,    9,   24,    5,    1,    8,    6,  941]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 客戶流失分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://raw.githubusercontent.com/ywchiu/tibamedl/master/Data/customer_churn.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "1    KS             128  area_code_415                 no             yes   \n",
       "2    OH             107  area_code_415                 no             yes   \n",
       "3    NJ             137  area_code_415                 no              no   \n",
       "4    OH              84  area_code_408                yes              no   \n",
       "5    OK              75  area_code_415                yes              no   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "1                     25              265.1              110   \n",
       "2                     26              161.6              123   \n",
       "3                      0              243.4              114   \n",
       "4                      0              299.4               71   \n",
       "5                      0              166.7              113   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "1             45.07              197.4               99             16.78   \n",
       "2             27.47              195.5              103             16.62   \n",
       "3             41.38              121.2              110             10.30   \n",
       "4             50.90               61.9               88              5.26   \n",
       "5             28.34              148.3              122             12.61   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "1                244.7                 91               11.01   \n",
       "2                254.4                103               11.45   \n",
       "3                162.6                104                7.32   \n",
       "4                196.9                 89                8.86   \n",
       "5                186.9                121                8.41   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "1                10.0                 3               2.70   \n",
       "2                13.7                 3               3.70   \n",
       "3                12.2                 5               3.29   \n",
       "4                 6.6                 7               1.78   \n",
       "5                10.1                 3               2.73   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "1                              1    no  \n",
       "2                              1    no  \n",
       "3                              0    no  \n",
       "4                              2    no  \n",
       "5                              3    no  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[ row , col  ]\n",
    "X = dataset.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 1 to 3333\n",
      "Data columns (total 17 columns):\n",
      "international_plan               3333 non-null object\n",
      "voice_mail_plan                  3333 non-null object\n",
      "number_vmail_messages            3333 non-null int64\n",
      "total_day_minutes                3333 non-null float64\n",
      "total_day_calls                  3333 non-null int64\n",
      "total_day_charge                 3333 non-null float64\n",
      "total_eve_minutes                3333 non-null float64\n",
      "total_eve_calls                  3333 non-null int64\n",
      "total_eve_charge                 3333 non-null float64\n",
      "total_night_minutes              3333 non-null float64\n",
      "total_night_calls                3333 non-null int64\n",
      "total_night_charge               3333 non-null float64\n",
      "total_intl_minutes               3333 non-null float64\n",
      "total_intl_calls                 3333 non-null int64\n",
      "total_intl_charge                3333 non-null float64\n",
      "number_customer_service_calls    3333 non-null int64\n",
      "churn                            3333 non-null object\n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 468.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['international_plan'] = X['international_plan'].map(lambda e : 1 if e == 'yes' else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['voice_mail_plan'] = X['voice_mail_plan'].map(lambda e : 1 if e == 'yes' else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['churn'] = X['churn'].map(lambda e : 1 if e == 'yes' else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 1 to 3333\n",
      "Data columns (total 17 columns):\n",
      "international_plan               3333 non-null int64\n",
      "voice_mail_plan                  3333 non-null int64\n",
      "number_vmail_messages            3333 non-null int64\n",
      "total_day_minutes                3333 non-null float64\n",
      "total_day_calls                  3333 non-null int64\n",
      "total_day_charge                 3333 non-null float64\n",
      "total_eve_minutes                3333 non-null float64\n",
      "total_eve_calls                  3333 non-null int64\n",
      "total_eve_charge                 3333 non-null float64\n",
      "total_night_minutes              3333 non-null float64\n",
      "total_night_calls                3333 non-null int64\n",
      "total_night_charge               3333 non-null float64\n",
      "total_intl_minutes               3333 non-null float64\n",
      "total_intl_calls                 3333 non-null int64\n",
      "total_intl_charge                3333 non-null float64\n",
      "number_customer_service_calls    3333 non-null int64\n",
      "churn                            3333 non-null int64\n",
      "dtypes: float64(8), int64(9)\n",
      "memory usage: 468.7 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2666, 16)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667, 16)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.11557817, -0.61579486, -0.58944097, ...,  0.21418988,\n",
       "        -0.33633574, -1.17967998],\n",
       "       [-0.32096771,  1.62391742,  2.06354095, ..., -0.60566687,\n",
       "        -0.08616319,  0.33819011],\n",
       "       [-0.32096771, -0.61579486, -0.58944097, ..., -0.19573849,\n",
       "         0.8091912 ,  1.09712515],\n",
       "       ...,\n",
       "       [-0.32096771, -0.61579486, -0.58944097, ..., -0.60566687,\n",
       "         0.55901865, -0.42074493],\n",
       "       [ 3.11557817, -0.61579486, -0.58944097, ..., -1.42552363,\n",
       "        -0.83668084, -0.42074493],\n",
       "       [-0.32096771, -0.61579486, -0.58944097, ..., -0.19573849,\n",
       "        -0.29683481,  1.09712515]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定網路參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 8 \n",
    "n_hidden_2 = 8 \n",
    "n_input    = 16 \n",
    "n_classes  = 1 \n",
    "\n",
    "training_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2666 samples, validate on 667 samples\n",
      "Epoch 1/100\n",
      "2666/2666 [==============================] - 0s 79us/step - loss: 0.8837 - acc: 0.3286 - val_loss: 0.7360 - val_acc: 0.5337\n",
      "Epoch 2/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.6401 - acc: 0.6887 - val_loss: 0.5800 - val_acc: 0.7751\n",
      "Epoch 3/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.5387 - acc: 0.8256 - val_loss: 0.5078 - val_acc: 0.8411\n",
      "Epoch 4/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4897 - acc: 0.8500 - val_loss: 0.4692 - val_acc: 0.8561\n",
      "Epoch 5/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4630 - acc: 0.8548 - val_loss: 0.4472 - val_acc: 0.8681\n",
      "Epoch 6/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4473 - acc: 0.8545 - val_loss: 0.4329 - val_acc: 0.8681\n",
      "Epoch 7/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.4369 - acc: 0.8530 - val_loss: 0.4230 - val_acc: 0.8696\n",
      "Epoch 8/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4296 - acc: 0.8522 - val_loss: 0.4156 - val_acc: 0.8681\n",
      "Epoch 9/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4240 - acc: 0.8515 - val_loss: 0.4098 - val_acc: 0.8681\n",
      "Epoch 10/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4195 - acc: 0.8515 - val_loss: 0.4049 - val_acc: 0.8681\n",
      "Epoch 11/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4157 - acc: 0.8526 - val_loss: 0.4010 - val_acc: 0.8681\n",
      "Epoch 12/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4124 - acc: 0.8522 - val_loss: 0.3974 - val_acc: 0.8681\n",
      "Epoch 13/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4094 - acc: 0.8526 - val_loss: 0.3941 - val_acc: 0.8681\n",
      "Epoch 14/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.4065 - acc: 0.8522 - val_loss: 0.3911 - val_acc: 0.8681\n",
      "Epoch 15/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4038 - acc: 0.8526 - val_loss: 0.3883 - val_acc: 0.8681\n",
      "Epoch 16/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.4012 - acc: 0.8526 - val_loss: 0.3856 - val_acc: 0.8681\n",
      "Epoch 17/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3987 - acc: 0.8526 - val_loss: 0.3831 - val_acc: 0.8681\n",
      "Epoch 18/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3963 - acc: 0.8533 - val_loss: 0.3807 - val_acc: 0.8681\n",
      "Epoch 19/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3940 - acc: 0.8533 - val_loss: 0.3783 - val_acc: 0.8681\n",
      "Epoch 20/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3916 - acc: 0.8537 - val_loss: 0.3760 - val_acc: 0.8681\n",
      "Epoch 21/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3894 - acc: 0.8537 - val_loss: 0.3738 - val_acc: 0.8696\n",
      "Epoch 22/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3872 - acc: 0.8533 - val_loss: 0.3715 - val_acc: 0.8696\n",
      "Epoch 23/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3850 - acc: 0.8545 - val_loss: 0.3694 - val_acc: 0.8696\n",
      "Epoch 24/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3829 - acc: 0.8541 - val_loss: 0.3672 - val_acc: 0.8696\n",
      "Epoch 25/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3807 - acc: 0.8541 - val_loss: 0.3652 - val_acc: 0.8681\n",
      "Epoch 26/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3786 - acc: 0.8548 - val_loss: 0.3631 - val_acc: 0.8681\n",
      "Epoch 27/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3766 - acc: 0.8552 - val_loss: 0.3611 - val_acc: 0.8681\n",
      "Epoch 28/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3745 - acc: 0.8560 - val_loss: 0.3590 - val_acc: 0.8681\n",
      "Epoch 29/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3724 - acc: 0.8567 - val_loss: 0.3570 - val_acc: 0.8681\n",
      "Epoch 30/100\n",
      "2666/2666 [==============================] - 0s 11us/step - loss: 0.3704 - acc: 0.8571 - val_loss: 0.3551 - val_acc: 0.8681\n",
      "Epoch 31/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3684 - acc: 0.8582 - val_loss: 0.3532 - val_acc: 0.8681\n",
      "Epoch 32/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3664 - acc: 0.8597 - val_loss: 0.3513 - val_acc: 0.8696\n",
      "Epoch 33/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3645 - acc: 0.8616 - val_loss: 0.3493 - val_acc: 0.8711\n",
      "Epoch 34/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3626 - acc: 0.8627 - val_loss: 0.3474 - val_acc: 0.8726\n",
      "Epoch 35/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3607 - acc: 0.8631 - val_loss: 0.3457 - val_acc: 0.8726\n",
      "Epoch 36/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3587 - acc: 0.8631 - val_loss: 0.3438 - val_acc: 0.8741\n",
      "Epoch 37/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3568 - acc: 0.8635 - val_loss: 0.3420 - val_acc: 0.8741\n",
      "Epoch 38/100\n",
      "2666/2666 [==============================] - 0s 11us/step - loss: 0.3549 - acc: 0.8642 - val_loss: 0.3402 - val_acc: 0.8771\n",
      "Epoch 39/100\n",
      "2666/2666 [==============================] - 0s 10us/step - loss: 0.3530 - acc: 0.8653 - val_loss: 0.3384 - val_acc: 0.8771\n",
      "Epoch 40/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3511 - acc: 0.8661 - val_loss: 0.3366 - val_acc: 0.8771\n",
      "Epoch 41/100\n",
      "2666/2666 [==============================] - 0s 12us/step - loss: 0.3492 - acc: 0.8668 - val_loss: 0.3348 - val_acc: 0.8771\n",
      "Epoch 42/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3474 - acc: 0.8676 - val_loss: 0.3332 - val_acc: 0.8786\n",
      "Epoch 43/100\n",
      "2666/2666 [==============================] - 0s 11us/step - loss: 0.3455 - acc: 0.8687 - val_loss: 0.3314 - val_acc: 0.8786\n",
      "Epoch 44/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3437 - acc: 0.8695 - val_loss: 0.3297 - val_acc: 0.8786\n",
      "Epoch 45/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3419 - acc: 0.8698 - val_loss: 0.3281 - val_acc: 0.8786\n",
      "Epoch 46/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3401 - acc: 0.8706 - val_loss: 0.3265 - val_acc: 0.8786\n",
      "Epoch 47/100\n",
      "2666/2666 [==============================] - 0s 11us/step - loss: 0.3384 - acc: 0.8736 - val_loss: 0.3250 - val_acc: 0.8786\n",
      "Epoch 48/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3367 - acc: 0.8751 - val_loss: 0.3234 - val_acc: 0.8771\n",
      "Epoch 49/100\n",
      "2666/2666 [==============================] - 0s 10us/step - loss: 0.3350 - acc: 0.8755 - val_loss: 0.3219 - val_acc: 0.8756\n",
      "Epoch 50/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3333 - acc: 0.8755 - val_loss: 0.3205 - val_acc: 0.8771\n",
      "Epoch 51/100\n",
      "2666/2666 [==============================] - 0s 10us/step - loss: 0.3315 - acc: 0.8751 - val_loss: 0.3190 - val_acc: 0.8786\n",
      "Epoch 52/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3298 - acc: 0.8758 - val_loss: 0.3175 - val_acc: 0.8801\n",
      "Epoch 53/100\n",
      "2666/2666 [==============================] - 0s 10us/step - loss: 0.3282 - acc: 0.8766 - val_loss: 0.3160 - val_acc: 0.8801\n",
      "Epoch 54/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3265 - acc: 0.8758 - val_loss: 0.3145 - val_acc: 0.8801\n",
      "Epoch 55/100\n",
      "2666/2666 [==============================] - 0s 10us/step - loss: 0.3249 - acc: 0.8770 - val_loss: 0.3132 - val_acc: 0.8786\n",
      "Epoch 56/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.3233 - acc: 0.8773 - val_loss: 0.3118 - val_acc: 0.8831\n",
      "Epoch 57/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3217 - acc: 0.8773 - val_loss: 0.3106 - val_acc: 0.8816\n",
      "Epoch 58/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3201 - acc: 0.8792 - val_loss: 0.3093 - val_acc: 0.8861\n",
      "Epoch 59/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3186 - acc: 0.8803 - val_loss: 0.3079 - val_acc: 0.8846\n",
      "Epoch 60/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3170 - acc: 0.8800 - val_loss: 0.3067 - val_acc: 0.8831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3156 - acc: 0.8811 - val_loss: 0.3055 - val_acc: 0.8846\n",
      "Epoch 62/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3141 - acc: 0.8826 - val_loss: 0.3041 - val_acc: 0.8846\n",
      "Epoch 63/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3126 - acc: 0.8837 - val_loss: 0.3028 - val_acc: 0.8861\n",
      "Epoch 64/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3111 - acc: 0.8841 - val_loss: 0.3016 - val_acc: 0.8861\n",
      "Epoch 65/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.3096 - acc: 0.8848 - val_loss: 0.3004 - val_acc: 0.8846\n",
      "Epoch 66/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.3081 - acc: 0.8848 - val_loss: 0.2993 - val_acc: 0.8861\n",
      "Epoch 67/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3066 - acc: 0.8852 - val_loss: 0.2982 - val_acc: 0.8876\n",
      "Epoch 68/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.3051 - acc: 0.8867 - val_loss: 0.2973 - val_acc: 0.8906\n",
      "Epoch 69/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.3036 - acc: 0.8897 - val_loss: 0.2961 - val_acc: 0.8891\n",
      "Epoch 70/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3022 - acc: 0.8890 - val_loss: 0.2948 - val_acc: 0.8891\n",
      "Epoch 71/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.3007 - acc: 0.8897 - val_loss: 0.2937 - val_acc: 0.8906\n",
      "Epoch 72/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2992 - acc: 0.8893 - val_loss: 0.2926 - val_acc: 0.8921\n",
      "Epoch 73/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2978 - acc: 0.8901 - val_loss: 0.2913 - val_acc: 0.8936\n",
      "Epoch 74/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2963 - acc: 0.8908 - val_loss: 0.2901 - val_acc: 0.8966\n",
      "Epoch 75/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2949 - acc: 0.8901 - val_loss: 0.2890 - val_acc: 0.8966\n",
      "Epoch 76/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2934 - acc: 0.8931 - val_loss: 0.2879 - val_acc: 0.8966\n",
      "Epoch 77/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2921 - acc: 0.8923 - val_loss: 0.2869 - val_acc: 0.8966\n",
      "Epoch 78/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2907 - acc: 0.8942 - val_loss: 0.2858 - val_acc: 0.8966\n",
      "Epoch 79/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2893 - acc: 0.8946 - val_loss: 0.2847 - val_acc: 0.8981\n",
      "Epoch 80/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.2881 - acc: 0.8950 - val_loss: 0.2837 - val_acc: 0.8996\n",
      "Epoch 81/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2867 - acc: 0.8942 - val_loss: 0.2828 - val_acc: 0.8996\n",
      "Epoch 82/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.2854 - acc: 0.8942 - val_loss: 0.2819 - val_acc: 0.8981\n",
      "Epoch 83/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2841 - acc: 0.8950 - val_loss: 0.2809 - val_acc: 0.8981\n",
      "Epoch 84/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2827 - acc: 0.8946 - val_loss: 0.2801 - val_acc: 0.9010\n",
      "Epoch 85/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2814 - acc: 0.8953 - val_loss: 0.2792 - val_acc: 0.8996\n",
      "Epoch 86/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.2801 - acc: 0.8983 - val_loss: 0.2781 - val_acc: 0.8996\n",
      "Epoch 87/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2788 - acc: 0.8976 - val_loss: 0.2772 - val_acc: 0.8996\n",
      "Epoch 88/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2775 - acc: 0.8995 - val_loss: 0.2761 - val_acc: 0.9010\n",
      "Epoch 89/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2762 - acc: 0.9002 - val_loss: 0.2750 - val_acc: 0.9040\n",
      "Epoch 90/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2750 - acc: 0.9014 - val_loss: 0.2742 - val_acc: 0.9055\n",
      "Epoch 91/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2737 - acc: 0.9021 - val_loss: 0.2731 - val_acc: 0.9055\n",
      "Epoch 92/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2726 - acc: 0.9032 - val_loss: 0.2720 - val_acc: 0.9055\n",
      "Epoch 93/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2713 - acc: 0.9040 - val_loss: 0.2710 - val_acc: 0.9055\n",
      "Epoch 94/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2701 - acc: 0.9047 - val_loss: 0.2701 - val_acc: 0.9055\n",
      "Epoch 95/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2689 - acc: 0.9036 - val_loss: 0.2693 - val_acc: 0.9070\n",
      "Epoch 96/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.2679 - acc: 0.9047 - val_loss: 0.2684 - val_acc: 0.9070\n",
      "Epoch 97/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2666 - acc: 0.9059 - val_loss: 0.2675 - val_acc: 0.9085\n",
      "Epoch 98/100\n",
      "2666/2666 [==============================] - 0s 9us/step - loss: 0.2655 - acc: 0.9070 - val_loss: 0.2667 - val_acc: 0.9100\n",
      "Epoch 99/100\n",
      "2666/2666 [==============================] - 0s 7us/step - loss: 0.2644 - acc: 0.9074 - val_loss: 0.2659 - val_acc: 0.9085\n",
      "Epoch 100/100\n",
      "2666/2666 [==============================] - 0s 8us/step - loss: 0.2633 - acc: 0.9081 - val_loss: 0.2648 - val_acc: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158cbfd0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape=(n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = training_epochs,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (model.predict(X_test) > 0.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085457271364318"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[563,  16],\n",
       "       [ 45,  43]], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP: True Positive\n",
    "# FP: False Positive\n",
    "# FN: False Negative\n",
    "# TN: True Negative\n",
    "#[TP:563,  FP:16],\n",
    "#[FN:45,  TN:43]\n",
    "#https://image.slidesharecdn.com/qmethodsday14-2014-141013122633-conversion-gate02/95/quantitative-methods-for-lawyers-class-14-power-laws-hypothesis-testing-statistical-significance-professor-daniel-martin-katz-22-638.jpg?cb=1448049863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-20000 * (16 + 43 )\n",
    "#-2000 * (45 + 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 客戶流失數據分析二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "dataset = pandas.read_csv('https://raw.githubusercontent.com/ywchiu/tibamedl/master/Data/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.get_dummies(X['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,geo], axis = 1)\n",
    "del X['Spain']\n",
    "del X['Geography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "France             10000 non-null uint8\n",
      "Germany            10000 non-null uint8\n",
      "dtypes: float64(2), int64(6), object(1), uint8(2)\n",
      "memory usage: 722.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Gender'] = X['Gender'].map(lambda e: 1 if e =='Male' else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  France  Germany  \n",
       "0               1        101348.88       1        0  \n",
       "1               1        112542.58       0        0  \n",
       "2               0        113931.57       1        0  \n",
       "3               0         93826.63       1        0  \n",
       "4               1         79084.10       0        0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將資料區分為訓練與測試資料集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將資料標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定網路參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 6 \n",
    "n_hidden_2 = 6 \n",
    "n_input    = 11\n",
    "n_classes  = 1 \n",
    "\n",
    "training_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.7124 - acc: 0.5808 - val_loss: 0.6428 - val_acc: 0.7120\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.6055 - acc: 0.7586 - val_loss: 0.5759 - val_acc: 0.7875\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5606 - acc: 0.7882 - val_loss: 0.5426 - val_acc: 0.8055\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5372 - acc: 0.7939 - val_loss: 0.5237 - val_acc: 0.8055\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5235 - acc: 0.7946 - val_loss: 0.5117 - val_acc: 0.8045\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5144 - acc: 0.7949 - val_loss: 0.5032 - val_acc: 0.8035\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5078 - acc: 0.7947 - val_loss: 0.4967 - val_acc: 0.8035\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.5027 - acc: 0.7947 - val_loss: 0.4915 - val_acc: 0.8035\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4984 - acc: 0.7947 - val_loss: 0.4870 - val_acc: 0.8035\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4946 - acc: 0.7947 - val_loss: 0.4830 - val_acc: 0.8035\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4912 - acc: 0.7947 - val_loss: 0.4794 - val_acc: 0.8035\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4881 - acc: 0.7946 - val_loss: 0.4760 - val_acc: 0.8040\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4852 - acc: 0.7946 - val_loss: 0.4728 - val_acc: 0.8045\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4823 - acc: 0.7950 - val_loss: 0.4698 - val_acc: 0.8045\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4795 - acc: 0.7953 - val_loss: 0.4669 - val_acc: 0.8045\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4769 - acc: 0.7956 - val_loss: 0.4640 - val_acc: 0.8045\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4742 - acc: 0.7961 - val_loss: 0.4611 - val_acc: 0.8055\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4715 - acc: 0.7965 - val_loss: 0.4584 - val_acc: 0.8050\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4688 - acc: 0.7975 - val_loss: 0.4556 - val_acc: 0.8065\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4661 - acc: 0.7985 - val_loss: 0.4529 - val_acc: 0.8070\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4633 - acc: 0.7989 - val_loss: 0.4502 - val_acc: 0.8060\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4606 - acc: 0.8000 - val_loss: 0.4475 - val_acc: 0.8055\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4578 - acc: 0.8002 - val_loss: 0.4448 - val_acc: 0.8040\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4550 - acc: 0.8009 - val_loss: 0.4421 - val_acc: 0.8080\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4522 - acc: 0.8029 - val_loss: 0.4394 - val_acc: 0.8090\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4494 - acc: 0.8025 - val_loss: 0.4368 - val_acc: 0.8110\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4467 - acc: 0.8039 - val_loss: 0.4342 - val_acc: 0.8130\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4440 - acc: 0.8047 - val_loss: 0.4318 - val_acc: 0.8135\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4414 - acc: 0.8060 - val_loss: 0.4294 - val_acc: 0.8140\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4389 - acc: 0.8071 - val_loss: 0.4271 - val_acc: 0.8150\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4364 - acc: 0.8077 - val_loss: 0.4249 - val_acc: 0.8160\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4341 - acc: 0.8081 - val_loss: 0.4227 - val_acc: 0.8165\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4318 - acc: 0.8100 - val_loss: 0.4206 - val_acc: 0.8170\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4296 - acc: 0.8102 - val_loss: 0.4186 - val_acc: 0.8175\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4274 - acc: 0.8119 - val_loss: 0.4167 - val_acc: 0.8200\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4253 - acc: 0.8121 - val_loss: 0.4149 - val_acc: 0.8215\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.4232 - acc: 0.8145 - val_loss: 0.4130 - val_acc: 0.8215\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4212 - acc: 0.8154 - val_loss: 0.4111 - val_acc: 0.8225\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4191 - acc: 0.8156 - val_loss: 0.4093 - val_acc: 0.8245\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4171 - acc: 0.8165 - val_loss: 0.4074 - val_acc: 0.8255\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4152 - acc: 0.8175 - val_loss: 0.4055 - val_acc: 0.8265\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4132 - acc: 0.8193 - val_loss: 0.4037 - val_acc: 0.8265\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4113 - acc: 0.8211 - val_loss: 0.4021 - val_acc: 0.8270\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4094 - acc: 0.8215 - val_loss: 0.4005 - val_acc: 0.8270\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4076 - acc: 0.8223 - val_loss: 0.3988 - val_acc: 0.8270\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4058 - acc: 0.8237 - val_loss: 0.3971 - val_acc: 0.8285\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4040 - acc: 0.8250 - val_loss: 0.3955 - val_acc: 0.8270\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4022 - acc: 0.8256 - val_loss: 0.3940 - val_acc: 0.8280\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4005 - acc: 0.8272 - val_loss: 0.3923 - val_acc: 0.8300\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3987 - acc: 0.8283 - val_loss: 0.3908 - val_acc: 0.8305\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3971 - acc: 0.8294 - val_loss: 0.3894 - val_acc: 0.8315\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3954 - acc: 0.8294 - val_loss: 0.3880 - val_acc: 0.8330\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3937 - acc: 0.8313 - val_loss: 0.3866 - val_acc: 0.8325\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3921 - acc: 0.8319 - val_loss: 0.3852 - val_acc: 0.8330\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3905 - acc: 0.8319 - val_loss: 0.3838 - val_acc: 0.8345\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3890 - acc: 0.8332 - val_loss: 0.3825 - val_acc: 0.8355\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3874 - acc: 0.8342 - val_loss: 0.3812 - val_acc: 0.8365\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3860 - acc: 0.8349 - val_loss: 0.3799 - val_acc: 0.8375\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3846 - acc: 0.8364 - val_loss: 0.3788 - val_acc: 0.8390\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3833 - acc: 0.8350 - val_loss: 0.3776 - val_acc: 0.8390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3820 - acc: 0.8354 - val_loss: 0.3764 - val_acc: 0.8385\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3807 - acc: 0.8366 - val_loss: 0.3755 - val_acc: 0.8395\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3796 - acc: 0.8380 - val_loss: 0.3744 - val_acc: 0.8395\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3785 - acc: 0.8374 - val_loss: 0.3735 - val_acc: 0.8395\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3774 - acc: 0.8376 - val_loss: 0.3726 - val_acc: 0.8410\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3764 - acc: 0.8377 - val_loss: 0.3716 - val_acc: 0.8410\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3755 - acc: 0.8391 - val_loss: 0.3710 - val_acc: 0.8430\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3746 - acc: 0.8394 - val_loss: 0.3701 - val_acc: 0.8430\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3738 - acc: 0.8401 - val_loss: 0.3696 - val_acc: 0.8445\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3730 - acc: 0.8405 - val_loss: 0.3689 - val_acc: 0.8440\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3722 - acc: 0.8414 - val_loss: 0.3681 - val_acc: 0.8425\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3714 - acc: 0.8414 - val_loss: 0.3676 - val_acc: 0.8415\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3708 - acc: 0.8432 - val_loss: 0.3671 - val_acc: 0.8420\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3701 - acc: 0.8422 - val_loss: 0.3667 - val_acc: 0.8430\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3694 - acc: 0.8438 - val_loss: 0.3659 - val_acc: 0.8425\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3689 - acc: 0.8441 - val_loss: 0.3655 - val_acc: 0.8430\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3683 - acc: 0.8447 - val_loss: 0.3652 - val_acc: 0.8420\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3678 - acc: 0.8450 - val_loss: 0.3648 - val_acc: 0.8430\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3674 - acc: 0.8446 - val_loss: 0.3645 - val_acc: 0.8445\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3669 - acc: 0.8454 - val_loss: 0.3642 - val_acc: 0.8455\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3665 - acc: 0.8454 - val_loss: 0.3638 - val_acc: 0.8455\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3661 - acc: 0.8459 - val_loss: 0.3638 - val_acc: 0.8435\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3657 - acc: 0.8449 - val_loss: 0.3634 - val_acc: 0.8445\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3654 - acc: 0.8451 - val_loss: 0.3631 - val_acc: 0.8445\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3651 - acc: 0.8457 - val_loss: 0.3630 - val_acc: 0.8450\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3647 - acc: 0.8454 - val_loss: 0.3627 - val_acc: 0.8450\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3644 - acc: 0.8455 - val_loss: 0.3625 - val_acc: 0.8450\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3642 - acc: 0.8459 - val_loss: 0.3624 - val_acc: 0.8435\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3639 - acc: 0.8450 - val_loss: 0.3622 - val_acc: 0.8455\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3636 - acc: 0.8451 - val_loss: 0.3621 - val_acc: 0.8445\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3634 - acc: 0.8450 - val_loss: 0.3621 - val_acc: 0.8435\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3632 - acc: 0.8451 - val_loss: 0.3619 - val_acc: 0.8445\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3630 - acc: 0.8445 - val_loss: 0.3617 - val_acc: 0.8445\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3627 - acc: 0.8461 - val_loss: 0.3619 - val_acc: 0.8460\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3626 - acc: 0.8439 - val_loss: 0.3616 - val_acc: 0.8460\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3624 - acc: 0.8447 - val_loss: 0.3614 - val_acc: 0.8460\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3622 - acc: 0.8445 - val_loss: 0.3613 - val_acc: 0.8465\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3620 - acc: 0.8445 - val_loss: 0.3612 - val_acc: 0.8475\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3619 - acc: 0.8451 - val_loss: 0.3612 - val_acc: 0.8475\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3618 - acc: 0.8445 - val_loss: 0.3611 - val_acc: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15fee128>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape = (n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = training_epochs,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (model.predict(X_test) > 0.5).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1527,   80],\n",
       "       [ 226,  167]], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改優化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.5562 - acc: 0.7944 - val_loss: 0.5143 - val_acc: 0.8035\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.5028 - acc: 0.7945 - val_loss: 0.4759 - val_acc: 0.8035\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4779 - acc: 0.7945 - val_loss: 0.4558 - val_acc: 0.8035\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4632 - acc: 0.7945 - val_loss: 0.4438 - val_acc: 0.8035\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4532 - acc: 0.7945 - val_loss: 0.4360 - val_acc: 0.8035\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4462 - acc: 0.7945 - val_loss: 0.4298 - val_acc: 0.8035\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4407 - acc: 0.7945 - val_loss: 0.4253 - val_acc: 0.8035\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4362 - acc: 0.7945 - val_loss: 0.4220 - val_acc: 0.8035\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4325 - acc: 0.7945 - val_loss: 0.4193 - val_acc: 0.8035\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4295 - acc: 0.7945 - val_loss: 0.4169 - val_acc: 0.8035\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4273 - acc: 0.7945 - val_loss: 0.4154 - val_acc: 0.8035\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4251 - acc: 0.7945 - val_loss: 0.4136 - val_acc: 0.8035\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4233 - acc: 0.7945 - val_loss: 0.4117 - val_acc: 0.8035\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4214 - acc: 0.8001 - val_loss: 0.4102 - val_acc: 0.8160\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4197 - acc: 0.8130 - val_loss: 0.4088 - val_acc: 0.8185\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4177 - acc: 0.8131 - val_loss: 0.4071 - val_acc: 0.8200\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.4159 - acc: 0.8142 - val_loss: 0.4057 - val_acc: 0.8180\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4142 - acc: 0.8161 - val_loss: 0.4041 - val_acc: 0.8220\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4125 - acc: 0.8165 - val_loss: 0.4026 - val_acc: 0.8205\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4110 - acc: 0.8185 - val_loss: 0.4014 - val_acc: 0.8215\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.4097 - acc: 0.8186 - val_loss: 0.4008 - val_acc: 0.8215\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4084 - acc: 0.8194 - val_loss: 0.3995 - val_acc: 0.8230\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.4069 - acc: 0.8191 - val_loss: 0.3983 - val_acc: 0.8210\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4058 - acc: 0.8184 - val_loss: 0.3974 - val_acc: 0.8225\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4044 - acc: 0.8191 - val_loss: 0.3970 - val_acc: 0.8200\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.4031 - acc: 0.8206 - val_loss: 0.3957 - val_acc: 0.8205\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.4016 - acc: 0.8200 - val_loss: 0.3949 - val_acc: 0.8205\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.4004 - acc: 0.8212 - val_loss: 0.3941 - val_acc: 0.8215\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3993 - acc: 0.8214 - val_loss: 0.3935 - val_acc: 0.8235\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3979 - acc: 0.8221 - val_loss: 0.3922 - val_acc: 0.8225\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3966 - acc: 0.8216 - val_loss: 0.3918 - val_acc: 0.8235\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3954 - acc: 0.8217 - val_loss: 0.3904 - val_acc: 0.8235\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3942 - acc: 0.8231 - val_loss: 0.3893 - val_acc: 0.8280\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3931 - acc: 0.8286 - val_loss: 0.3884 - val_acc: 0.8305\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3921 - acc: 0.8285 - val_loss: 0.3875 - val_acc: 0.8320\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3914 - acc: 0.8299 - val_loss: 0.3867 - val_acc: 0.8335\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3903 - acc: 0.8291 - val_loss: 0.3858 - val_acc: 0.8340\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3896 - acc: 0.8303 - val_loss: 0.3853 - val_acc: 0.8375\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3886 - acc: 0.8306 - val_loss: 0.3849 - val_acc: 0.8375\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3877 - acc: 0.8309 - val_loss: 0.3837 - val_acc: 0.8350\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3872 - acc: 0.8317 - val_loss: 0.3831 - val_acc: 0.8385\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3863 - acc: 0.8342 - val_loss: 0.3828 - val_acc: 0.8385\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3855 - acc: 0.8341 - val_loss: 0.3824 - val_acc: 0.8400\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3848 - acc: 0.8350 - val_loss: 0.3813 - val_acc: 0.8385\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3840 - acc: 0.8351 - val_loss: 0.3813 - val_acc: 0.8390\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3833 - acc: 0.8364 - val_loss: 0.3804 - val_acc: 0.8390\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3826 - acc: 0.8372 - val_loss: 0.3796 - val_acc: 0.8400\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3820 - acc: 0.8371 - val_loss: 0.3792 - val_acc: 0.8380\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3813 - acc: 0.8382 - val_loss: 0.3789 - val_acc: 0.8410\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3808 - acc: 0.8385 - val_loss: 0.3780 - val_acc: 0.8405\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3801 - acc: 0.8378 - val_loss: 0.3774 - val_acc: 0.8415\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3791 - acc: 0.8398 - val_loss: 0.3765 - val_acc: 0.8410\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3783 - acc: 0.8414 - val_loss: 0.3763 - val_acc: 0.8405\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3778 - acc: 0.8415 - val_loss: 0.3762 - val_acc: 0.8400\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3769 - acc: 0.8417 - val_loss: 0.3748 - val_acc: 0.8420\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3763 - acc: 0.8431 - val_loss: 0.3741 - val_acc: 0.8405\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3753 - acc: 0.8430 - val_loss: 0.3735 - val_acc: 0.8395\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3748 - acc: 0.8434 - val_loss: 0.3733 - val_acc: 0.8400\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3738 - acc: 0.8426 - val_loss: 0.3725 - val_acc: 0.8385\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3733 - acc: 0.8449 - val_loss: 0.3720 - val_acc: 0.8415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3724 - acc: 0.8445 - val_loss: 0.3716 - val_acc: 0.8405\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3720 - acc: 0.8445 - val_loss: 0.3708 - val_acc: 0.8420\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3712 - acc: 0.8460 - val_loss: 0.3705 - val_acc: 0.8415\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3708 - acc: 0.8457 - val_loss: 0.3695 - val_acc: 0.8425\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3697 - acc: 0.8451 - val_loss: 0.3693 - val_acc: 0.8425\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3690 - acc: 0.8467 - val_loss: 0.3686 - val_acc: 0.8405\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3685 - acc: 0.8459 - val_loss: 0.3673 - val_acc: 0.8415\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3679 - acc: 0.8467 - val_loss: 0.3670 - val_acc: 0.8425\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3672 - acc: 0.8469 - val_loss: 0.3662 - val_acc: 0.8410\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3667 - acc: 0.8469 - val_loss: 0.3659 - val_acc: 0.8400\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3666 - acc: 0.8456 - val_loss: 0.3650 - val_acc: 0.8410\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3659 - acc: 0.8472 - val_loss: 0.3654 - val_acc: 0.8430\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3654 - acc: 0.8482 - val_loss: 0.3644 - val_acc: 0.8435\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3650 - acc: 0.8476 - val_loss: 0.3647 - val_acc: 0.8445\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3646 - acc: 0.8485 - val_loss: 0.3636 - val_acc: 0.8430\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3643 - acc: 0.8487 - val_loss: 0.3633 - val_acc: 0.8445\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3640 - acc: 0.8490 - val_loss: 0.3633 - val_acc: 0.8440\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3636 - acc: 0.8501 - val_loss: 0.3629 - val_acc: 0.8450\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3634 - acc: 0.8492 - val_loss: 0.3624 - val_acc: 0.8455\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3631 - acc: 0.8494 - val_loss: 0.3628 - val_acc: 0.8470\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3626 - acc: 0.8500 - val_loss: 0.3619 - val_acc: 0.8450\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3626 - acc: 0.8504 - val_loss: 0.3612 - val_acc: 0.8465\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3623 - acc: 0.8510 - val_loss: 0.3615 - val_acc: 0.8450\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3597 - acc: 0.851 - 0s 9us/step - loss: 0.3621 - acc: 0.8499 - val_loss: 0.3611 - val_acc: 0.8460\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3615 - acc: 0.8505 - val_loss: 0.3615 - val_acc: 0.8460\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3615 - acc: 0.8509 - val_loss: 0.3605 - val_acc: 0.8475\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3611 - acc: 0.8501 - val_loss: 0.3606 - val_acc: 0.8475\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.3608 - acc: 0.8494 - val_loss: 0.3603 - val_acc: 0.8490\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3606 - acc: 0.8512 - val_loss: 0.3602 - val_acc: 0.8485\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3602 - acc: 0.8498 - val_loss: 0.3592 - val_acc: 0.8490\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3600 - acc: 0.8505 - val_loss: 0.3597 - val_acc: 0.8485\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.3600 - acc: 0.8513 - val_loss: 0.3597 - val_acc: 0.8490\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3598 - acc: 0.8506 - val_loss: 0.3589 - val_acc: 0.8485\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3592 - acc: 0.8501 - val_loss: 0.3587 - val_acc: 0.8480\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3591 - acc: 0.8510 - val_loss: 0.3590 - val_acc: 0.8495\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3589 - acc: 0.8516 - val_loss: 0.3585 - val_acc: 0.8485\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.3586 - acc: 0.8509 - val_loss: 0.3580 - val_acc: 0.8490\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.3582 - acc: 0.8506 - val_loss: 0.3589 - val_acc: 0.8500\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3585 - acc: 0.8511 - val_loss: 0.3580 - val_acc: 0.8490\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.3580 - acc: 0.8510 - val_loss: 0.3580 - val_acc: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15cadba8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape = (n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = training_epochs,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AdamW import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamw = AdamW(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0., weight_decay=0.025, batch_size=1, samples_per_epoch=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape = (n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.compile(optimizer = adamw, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = training_epochs,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn  = build_classifier, batch_size = 100, epochs = 15, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945000015199184"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015783695858088514"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier2():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn  = build_classifier2, batch_size = 100, epochs = 15, verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82875   , 0.82124999, 0.80124999, 0.79125001, 0.79125001,\n",
       "       0.82875001, 0.79624999, 0.76874999, 0.79375   , 0.80375   ])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8024999991059303"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01800173696690713"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "def build_classifier3():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn  = build_classifier2, batch_size = 100, epochs = 15, verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn  = build_classifier3, batch_size = 100, epochs = 15, verbose= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945000015199184"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015783695858088514"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier3, epochs = 10)\n",
    "parameters = {'batch_size': [25, 32]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803375"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較優化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def train_model(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    history = classifier.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=100,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_test, y_test))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = train_model('sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop_model = train_model('RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad_model = train_model('Adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "adadelta_model = train_model('Adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model = train_model('Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% pylab inline\n",
    "import matplotlib.pyplot  as plt\n",
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(sgd_model.epoch, sgd_model.history['acc'], label='SGD')\n",
    "plt.plot(rmsprop_model.epoch, rmsprop_model.history['acc'], label='RMSProp')\n",
    "plt.plot(adagrad_model.epoch, adagrad_model.history['acc'], label='AdaGrad')\n",
    "plt.plot(adadelta_model.epoch, adadelta_model.history['acc'], label='AdaDelta')\n",
    "plt.plot(adam_model.epoch, adam_model.history['acc'], label='Adam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
